{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:03:16.100976Z",
     "start_time": "2025-03-13T12:03:15.409354Z"
    }
   },
   "source": [
    "%pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Users/soumikdutta/PycharmProjects/pythonAIProject/.venv/bin/python -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T12:05:44.238715Z",
     "start_time": "2025-03-14T12:05:44.080288Z"
    }
   },
   "source": [
    "import os\n",
    "import grpc\n",
    "import logging\n",
    "import subprocess\n",
    "import com_sixt_service_genai_connector.genai_connector_pb2 as genai_connector_pb2\n",
    "import com_sixt_service_genai_connector.genai_connector_pb2_grpc as genai_connector_pb2_grpc\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "GRPC_HOST = \"grpc-stage.goorange.sixt.com:443\"\n",
    "\n",
    "\n",
    "def get_access_token():\n",
    "    try:\n",
    "        token_command = os.path.expanduser(\"~/go/bin/com.sixt.tool.get-token\")\n",
    "\n",
    "        result = subprocess.run(\n",
    "            [token_command, \"--env=stage\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"Failed to get access token: {e}\")\n",
    "        raise"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grpc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgrpc\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msubprocess\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'grpc'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(4))\n",
    "def send_chat_request(prompt, temperature=0, max_tokens=200, model=None):\n",
    "    if model is None:\n",
    "        model = \"goorange-engineers.gpt4o\"\n",
    "    access_token = get_access_token()\n",
    "    messages = [\n",
    "        genai_connector_pb2.Messages(\n",
    "            role=\"user\",\n",
    "            content=prompt\n",
    "        )\n",
    "    ]\n",
    "    request = genai_connector_pb2.ChatRequest(\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=messages,\n",
    "        model=model\n",
    "    )\n",
    "    metadata = [('authorization', f'Bearer {access_token}')]\n",
    "    try:\n",
    "        response = stub.Chat(request, metadata=metadata)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logger.info(f\"An error occurred: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Let's define gRPC channel and stub for communication with the GenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.secure_channel(GRPC_HOST, grpc.ssl_channel_credentials())\n",
    "stub = genai_connector_pb2_grpc.GenAIConnectorStub(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the required setup to send chat request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin.\n",
      "The capital of Italy is Rome.\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    'case1: give me germany capital',\n",
    "    \"case2: give me italy capital\"\n",
    "]\n",
    "for prompt in prompts:\n",
    "    response = send_chat_request(prompt)\n",
    "    print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
